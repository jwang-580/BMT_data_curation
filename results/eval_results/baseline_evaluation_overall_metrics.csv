macro_precision,macro_recall,macro_f1,macro_accuracy,micro_precision,micro_recall,micro_f1,overall_extraction_rate,overall_coverage,model
0.7184351692302329,0.9753760515382889,0.8083962679471307,0.7108571428571427,0.7199074074074074,0.9826224328593997,0.830995323981296,0.9874285714285715,0.9874285714285715,llama3.1_70b
0.7387375648585248,0.9526843619246204,0.8161304165617043,0.7177142857142855,0.7399842890809112,0.9597554763117677,0.8356620093147039,0.9699047619047619,0.9699047619047619,qwen3_30b-a3b-thinking-2507-fp16
0.7497142857142857,1.0,0.8494883100303183,0.7497142857142857,0.7497142857142857,1.0,0.8569562377531026,1.0,1.0,gemma-bmt
0.7898232475987882,0.9127121792191375,0.8408220422436449,0.7424761904761904,0.7948613376835236,0.9184731385485391,0.8522081329252295,0.9340952380952382,0.9340952380952382,medgemma_27b_fp16
0.7726040601828615,0.9341375130618016,0.8397482689501476,0.7417142857142855,0.7769353551476457,0.9424007744433688,0.8517060367454068,0.9546666666666667,0.9546666666666667,gemma3_27b-it-fp16
